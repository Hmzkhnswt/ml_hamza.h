{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "data = datasets.load_breast_cancer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data[\"data\"], columns = data[\"feature_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"target\"] = data[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness   \n",
       "0        17.99         10.38          122.80     1001.0          0.11840  \\\n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry   \n",
       "0           0.27760          0.3001              0.14710         0.2419  \\\n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area   \n",
       "0                 0.07871  ...          17.33           184.60      2019.0  \\\n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points   \n",
       "0            0.1622             0.6656           0.7119                0.2654  \\\n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"target\"]\n",
    "X = df.drop(columns=[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness   \n",
       "0        17.99         10.38          122.80     1001.0          0.11840  \\\n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry   \n",
       "0           0.27760          0.3001              0.14710         0.2419  \\\n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area   \n",
       "0                 0.07871  ...          17.33           184.60      2019.0  \\\n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points   \n",
       "0            0.1622             0.6656           0.7119                0.2654  \\\n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote = SMOTE(random_state=42, sampling_strategy='auto')\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "X_resampled_df = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "y_resampled_df = pd.Series(y_resampled, name='target')\n",
    "resampled_df = pd.concat([X_resampled_df, y_resampled_df], axis=1)\n",
    "resampled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(714, 31)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    357\n",
       "1    357\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_df[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"darkgrid\") \n",
    "plt.figure(figsize=(6, 4))  \n",
    "sns.countplot(x=\"target\", data=resampled_df)\n",
    "\n",
    "plt.xlabel(\"Target\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of Target Variable\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_df.to_csv(\"diabetes_balanced.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_resampled\n",
    "y = y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "18/18 [==============================] - 1s 16ms/step - loss: 33.9755 - accuracy: 0.4553 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.7648 - accuracy: 0.6322 - val_loss: 0.1885 - val_accuracy: 0.9231\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5256 - accuracy: 0.8722 - val_loss: 0.2299 - val_accuracy: 0.9091\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3293 - accuracy: 0.9019 - val_loss: 0.1337 - val_accuracy: 0.9301\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.2883 - accuracy: 0.9072 - val_loss: 0.3807 - val_accuracy: 0.8601\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.2796 - accuracy: 0.9072 - val_loss: 0.4002 - val_accuracy: 0.8531\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.2540 - accuracy: 0.9212 - val_loss: 0.2551 - val_accuracy: 0.8951\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2819 - accuracy: 0.9072 - val_loss: 0.5428 - val_accuracy: 0.8042\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2505 - accuracy: 0.9159 - val_loss: 0.2782 - val_accuracy: 0.8811\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2607 - accuracy: 0.8984 - val_loss: 0.7577 - val_accuracy: 0.7552\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.2324 - accuracy: 0.9212 - val_loss: 0.4163 - val_accuracy: 0.8252\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3041 - accuracy: 0.8932 - val_loss: 0.7125 - val_accuracy: 0.7552\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.2319 - accuracy: 0.9264 - val_loss: 0.3638 - val_accuracy: 0.8252\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.2135 - accuracy: 0.9212 - val_loss: 0.4973 - val_accuracy: 0.7972\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2100 - accuracy: 0.9247 - val_loss: 0.4491 - val_accuracy: 0.7972\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2289 - accuracy: 0.9247 - val_loss: 0.2320 - val_accuracy: 0.8951\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1991 - accuracy: 0.9247 - val_loss: 0.3717 - val_accuracy: 0.8112\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2108 - accuracy: 0.9194 - val_loss: 0.6035 - val_accuracy: 0.7762\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3719 - accuracy: 0.8722 - val_loss: 0.7271 - val_accuracy: 0.7273\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.8809 - val_loss: 0.2429 - val_accuracy: 0.8881\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2492 - accuracy: 0.9194 - val_loss: 0.1113 - val_accuracy: 0.9301\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.8722 - val_loss: 0.0241 - val_accuracy: 0.9930\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2856 - accuracy: 0.9124 - val_loss: 0.1849 - val_accuracy: 0.9231\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.2196 - accuracy: 0.9317 - val_loss: 0.2225 - val_accuracy: 0.9161\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.2862 - accuracy: 0.8984 - val_loss: 0.1518 - val_accuracy: 0.9231\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1972 - accuracy: 0.9282 - val_loss: 0.3351 - val_accuracy: 0.8392\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1913 - accuracy: 0.9212 - val_loss: 0.2015 - val_accuracy: 0.9161\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2198 - accuracy: 0.9247 - val_loss: 0.6602 - val_accuracy: 0.7483\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1838 - accuracy: 0.9335 - val_loss: 0.4447 - val_accuracy: 0.7972\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2135 - accuracy: 0.9159 - val_loss: 0.2267 - val_accuracy: 0.8951\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1901 - accuracy: 0.9229 - val_loss: 0.1139 - val_accuracy: 0.9231\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2505 - accuracy: 0.9142 - val_loss: 0.0999 - val_accuracy: 0.9441\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2801 - accuracy: 0.9072 - val_loss: 0.0589 - val_accuracy: 0.9650\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3227 - accuracy: 0.8984 - val_loss: 0.0254 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.8564 - val_loss: 0.0694 - val_accuracy: 0.9580\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2091 - accuracy: 0.9194 - val_loss: 0.1334 - val_accuracy: 0.9301\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2023 - accuracy: 0.9370 - val_loss: 0.4555 - val_accuracy: 0.7972\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2192 - accuracy: 0.9159 - val_loss: 0.1740 - val_accuracy: 0.9231\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2332 - accuracy: 0.9019 - val_loss: 0.0426 - val_accuracy: 0.9790\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2592 - accuracy: 0.9019 - val_loss: 0.0909 - val_accuracy: 0.9510\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2394 - accuracy: 0.9177 - val_loss: 0.2781 - val_accuracy: 0.8671\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.2491 - accuracy: 0.9142 - val_loss: 0.0640 - val_accuracy: 0.9650\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2592 - accuracy: 0.9124 - val_loss: 0.1986 - val_accuracy: 0.9161\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1931 - accuracy: 0.9264 - val_loss: 0.4391 - val_accuracy: 0.8042\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1923 - accuracy: 0.9247 - val_loss: 0.0479 - val_accuracy: 0.9790\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2161 - accuracy: 0.9142 - val_loss: 0.4243 - val_accuracy: 0.8042\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.2339 - accuracy: 0.9212 - val_loss: 0.2150 - val_accuracy: 0.9091\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2010 - accuracy: 0.9264 - val_loss: 0.1495 - val_accuracy: 0.9231\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1863 - accuracy: 0.9264 - val_loss: 0.2301 - val_accuracy: 0.8951\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1882 - accuracy: 0.9247 - val_loss: 0.2788 - val_accuracy: 0.8741\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2665 - accuracy: 0.9037 - val_loss: 0.0575 - val_accuracy: 0.9650\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3558 - accuracy: 0.9002 - val_loss: 0.0523 - val_accuracy: 0.9720\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2752 - accuracy: 0.9089 - val_loss: 0.2312 - val_accuracy: 0.9091\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2892 - accuracy: 0.9107 - val_loss: 0.4030 - val_accuracy: 0.8042\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1984 - accuracy: 0.9212 - val_loss: 0.1818 - val_accuracy: 0.9231\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1890 - accuracy: 0.9264 - val_loss: 0.0513 - val_accuracy: 0.9790\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3214 - accuracy: 0.8914 - val_loss: 0.0513 - val_accuracy: 0.9720\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2790 - accuracy: 0.9002 - val_loss: 0.1519 - val_accuracy: 0.9231\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.2558 - accuracy: 0.9037 - val_loss: 0.1568 - val_accuracy: 0.9231\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.2346 - accuracy: 0.9072 - val_loss: 0.1084 - val_accuracy: 0.9301\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1704 - accuracy: 0.9282 - val_loss: 0.1789 - val_accuracy: 0.9231\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.2262 - accuracy: 0.9177 - val_loss: 0.0568 - val_accuracy: 0.9580\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2330 - accuracy: 0.9177 - val_loss: 0.0846 - val_accuracy: 0.9510\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2066 - accuracy: 0.9282 - val_loss: 1.1190 - val_accuracy: 0.6573\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2406 - accuracy: 0.9177 - val_loss: 0.7433 - val_accuracy: 0.7203\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1955 - accuracy: 0.9177 - val_loss: 0.5940 - val_accuracy: 0.7552\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1732 - accuracy: 0.9387 - val_loss: 0.2095 - val_accuracy: 0.9091\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1633 - accuracy: 0.9317 - val_loss: 0.2945 - val_accuracy: 0.8531\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1633 - accuracy: 0.9387 - val_loss: 1.1803 - val_accuracy: 0.6434\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1980 - accuracy: 0.9159 - val_loss: 0.8762 - val_accuracy: 0.6853\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1825 - accuracy: 0.9247 - val_loss: 0.4112 - val_accuracy: 0.8042\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1749 - accuracy: 0.9299 - val_loss: 0.3879 - val_accuracy: 0.8112\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1707 - accuracy: 0.9299 - val_loss: 0.1490 - val_accuracy: 0.9231\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1937 - accuracy: 0.9264 - val_loss: 0.0598 - val_accuracy: 0.9720\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2183 - accuracy: 0.9159 - val_loss: 0.1031 - val_accuracy: 0.9301\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1780 - accuracy: 0.9212 - val_loss: 0.0315 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2335 - accuracy: 0.9107 - val_loss: 0.3971 - val_accuracy: 0.8182\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.1632 - accuracy: 0.9370 - val_loss: 0.2736 - val_accuracy: 0.8811\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2443 - accuracy: 0.8932 - val_loss: 0.2324 - val_accuracy: 0.9021\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2002 - accuracy: 0.9212 - val_loss: 0.2381 - val_accuracy: 0.8951\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2944 - accuracy: 0.9054 - val_loss: 0.1675 - val_accuracy: 0.9231\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1905 - accuracy: 0.9229 - val_loss: 0.5151 - val_accuracy: 0.7622\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1845 - accuracy: 0.9299 - val_loss: 0.1518 - val_accuracy: 0.9231\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1605 - accuracy: 0.9264 - val_loss: 0.2543 - val_accuracy: 0.8951\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1961 - accuracy: 0.9107 - val_loss: 0.2260 - val_accuracy: 0.8881\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1875 - accuracy: 0.9247 - val_loss: 1.0504 - val_accuracy: 0.6573\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1835 - accuracy: 0.9264 - val_loss: 0.1754 - val_accuracy: 0.9231\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1946 - accuracy: 0.9335 - val_loss: 0.5134 - val_accuracy: 0.7552\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1771 - accuracy: 0.9317 - val_loss: 0.7857 - val_accuracy: 0.6993\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1736 - accuracy: 0.9282 - val_loss: 0.3358 - val_accuracy: 0.8252\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1564 - accuracy: 0.9387 - val_loss: 0.0931 - val_accuracy: 0.9301\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1731 - accuracy: 0.9299 - val_loss: 0.4558 - val_accuracy: 0.7902\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2415 - accuracy: 0.9124 - val_loss: 0.2333 - val_accuracy: 0.9021\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.1984 - accuracy: 0.9247 - val_loss: 0.1243 - val_accuracy: 0.9231\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1749 - accuracy: 0.9317 - val_loss: 0.6703 - val_accuracy: 0.7343\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2467 - accuracy: 0.9142 - val_loss: 0.9971 - val_accuracy: 0.6643\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3377 - accuracy: 0.8914 - val_loss: 0.3575 - val_accuracy: 0.8531\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1735 - accuracy: 0.9352 - val_loss: 0.0918 - val_accuracy: 0.9301\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1746 - accuracy: 0.9335 - val_loss: 0.0662 - val_accuracy: 0.9580\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.1688 - accuracy: 0.9335 - val_loss: 0.1633 - val_accuracy: 0.9231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1f6b14eec20>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=100, batch_size=32, verbose=1, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
